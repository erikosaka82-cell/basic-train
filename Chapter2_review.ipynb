{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPqEh/M99mKkobk/kHG3Cs4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EC7EqaVTRTj8"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["##Curve Fitting\n","曲線あてはめ\n","\n","### Generalized curve fitting\n","一般化された曲線あてはめ\n","\n","Principle:原理\n","\n","Given a set of data points, find a function $l=f(a)$ which \"best-fits\" the given points\n","一連のデータ点が与えられたとき、与えられた点に「最もよく適合する」関数 $l=f(a)$ を見つける。\n","\n","This function can then be used to estimate values of $l$ at other points\n","この関数は、その後、他の点での $l$ の値を推定するために使用できます。\n","\n","\n","Polynomial curve fitting 多項式曲線あてはめ\n","Suppose, the given data set consists of $n$ data point: $a_{i}$, $l_{i}$\n","与えられたデータセットが $n$ 個のデータ点 $a_{i}$, $l_{i}$ から成ると仮定します。\n","And the curve to be fitted to data is an $m^{th}$ order polynomial: $(m+1)<n$\n","そして、データにあてはめる曲線は $m$ 次の多項式であるとします。\n","\n"," $(m+1)<n$[cite_start]$l=f(a;x)=x_{0}+x_{1}a+\\cdots+x_{m-1}a^{m-1}+x_{m}a^{m}$\n","\n"," $l=f(a;x)=x_{0}+x_{1}a+\\cdots+x_{m-1}a^{m-1}+x_{m}a^{m}$ （多項式の式です）\n","\n"," The goal of curve fitting is to find the coefficients belonging the \"best-fit\" curve\n","\n"," 曲線あてはめの目標は、「最もよく適合する」曲線に属する係数を見つけることです\n","\n"," $\\hat{x}=[\\begin{matrix}\\hat{x}_{0}&\\hat{x}_{1}&\\cdots&\\hat{x}_{m}\\end{matrix}]^{T}$ [cite: 33]$\\hat{x}=[\\begin{matrix}\\hat{x}_{0}&\\hat{x}_{1}&\\cdots&\\hat{x}_{m}\\end{matrix}]^{T}$ （推定される係数ベクトルです）"],"metadata":{"id":"CMwCGFdRYG_M"}},{"cell_type":"code","source":["import numpy as np\n","\n","# 仮の観測データ（a: 入力, l: 出力）\n","a = np.array([1, 2, 3, 4, 5])     # x の値\n","l = np.array([2.1, 4.0, 5.9, 8.2, 10.1])  # y の値\n","\n","# 直線モデル f(a) = x0 + x1 * a\n","A = np.vstack([np.ones(len(a)), a]).T\n","\n","# 最小二乗解 x = (A^T A)^(-1) A^T l\n","x_hat = np.linalg.inv(A.T @ A) @ A.T @ l\n","print(\"推定された係数:\", x_hat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbT1bXTNbEEh","executionInfo":{"status":"ok","timestamp":1762185239917,"user_tz":420,"elapsed":15,"user":{"displayName":"Eriko Saka","userId":"06579929312182804218"}},"outputId":"d53379a3-0132-4d64-edbd-219397cbc2b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["推定された係数: [4.95492536e-15 2.02000000e+00]\n"]}]},{"cell_type":"markdown","source":["### 最小二乗法を Python に置き換える\n","<br>\n","\n","\n","このコードは、与えられたデータ点に対して最小二乗法を用いて直線フィッティングを行うものです。\n","\n","1. import numpy as np:\n","-数値計算ライブラリである NumPy をインポートし、np という別名で使用できるようにします。\n","\n","2. a = np.array([1, 2, 3, 4, 5]):\n","- 入力データ（x の値）を NumPy 配列 a として定義します。\n","\n","\n","3. l = np.array([2.1, 4.0, 5.9, 8.2, 10.1]):\n","- 出力データ（y の値）を NumPy 配列 l として定義します。\n","\n","\n","4. A = np.vstack([np.ones(len(a)), a]).T:\n","- これは、直線モデル $l = x_0 + x_1 * a$$l = x_0 + x_1 * a$ の係数 $x_0$$x_0$ と $x_1$$x_1$ を求めるための行列 $A$$A$ を構築しています。\n","   - np.ones(len(a)) は、a と同じ長さの要素がすべて 1 の配列を作成します。これは、定数項 $x_0$$x_0$ に対応します。\n","   - np.vstack([...]) は、これらの配列を縦に積み重ねて行列を作成します。\n","   - .T は、行列を転置します。これにより、各行がデータ点に対応し、各列が係数に対応する行列 A が作成されます。具体的には、A は以下のようになります。\n","<br>   \n","[[1. 1. 1. 1. 1.]<br>\n"," [1. 2. 3. 4. 5.]]\n","<br>\n"," を転置して\n"," <br>\n","\n","[[1. 1.]<br>\n"," [1. 2.]<br>\n"," [1. 3.]<br>\n"," [1. 4.]<br>\n"," [1. 5.]]<br>\n","<br>\n"," となります。\n"," <br>\n","\n","5. x_hat = np.linalg.inv(A.T @ A) @ A.T @ l:\n","- これは、最小二乗法の公式 $x = (A^T A)^{-1} A^T l$$x = (A^T A)^{-1} A^T l$ を用いて、最適な係数ベクトル $\\hat{x} = [x_0, x_1]^T$$\\hat{x} = [x_0, x_1]^T$ を計算しています。\n","   - A.T @ A は、$A$$A$ の転置行列と $A$$A$ の行列積です。\n","   - np.linalg.inv(...) は、その結果の逆行列を計算します。\n","   - @ A.T @ l は、逆行列と $A$$A$ の転置行列、そして出力データベクトル $l$$l$ の行列積を計算しており、これが最小二乗解である係数ベクトル $\\hat{x}$$\\hat{x}$ となります。\n","\n","\n","6. print(\"推定された係数:\", x_hat): 計算された係数 x_hat を表示します。この例では、x_hat の最初の要素が $x_0$$x_0$（切片）、2 番目の要素が $x_1$$x_1$（傾き）となります。\n","\n","\n","\n","このコードの実行結果は、与えられたデータ点に最もよくフィットする直線の切片と傾きを示しています。"],"metadata":{"id":"Q8GdZ1OtbH2K"}},{"cell_type":"markdown","source":["##最小二乗推定の品質評価基準（スライド10）\n","\n","### 1. なぜ「品質」を測る必要があるのか？\n","\n","最小二乗推定（LSE）は、観測データに最もよく合うようにモデルの未知のパラメーター（係数） を推定する手法です。しかし、観測データには必ずノイズ（誤差） が含まれています。\n","\n","私たちが知りたいのは以下の2点です。\n","\n","\n","- 残ったノイズの大きさ： モデルをあてはめた後、「それでも説明しきれなかったノイズ」はどれくらいの大きさなのか？（これが $σ_l^2$の役割です）\n","\n","- 推定したパラメーターの不確かさ： 推定した係数（例：直線の傾きや切片）は、どの程度の誤差を含んでいるのか？（これが $C_{x}$\n","  の役割です）\n","<br><br>\n","\n","### 2. 残差（Residuals v）とノイズ\n","\n","英語 (English)\t日本語訳 (Japanese Translation)\t解説\n","In LSE, the residuals v are considered representative of the random noise affecting measurements\tLSEでは、残差 v は、観測値に影響を与えるランダムノイズを代表するものと見なされます。\t残差とは、観測されたデータと、推定したモデルから計算された予測値との差です。これは、モデルで説明できなかった「ズレ」であり、観測に含まれるランダムな誤差（ノイズ） の大きさを反映していると考えます。\n","\n","<br><br>\n","\n","\n","### 3. 測定値の分散$σ_l^2$の推定（誤差の大きさ）\n","\n","$σ_l^2$は、単位重みあたりの分散と呼ばれ、観測値に含まれる平均的なノイズの大きさを示す指標です。\n","<br>\n","英語 (English)\t日本語訳 (Japanese Translation)\n","\n","<br><br>\n","解説\n","An unbiased estimate of $σ_l^2$  obtained from given data\n","与えられたデータから得られる$σ_l^2$ の不偏推定値です。\n","「不偏推定」とは、データのサンプルから計算した値が、本来の真の値（母集団の分散）と平均的にズレない、つまり偏り（バイアス）がないことを意味します。\n","$\\sigma_{l}^{2}=\\frac{1}{n-m}\t\t\\mathbf{v}$\n","<br><br>\n","\n","#### 3-1. 分子：残差の二乗和（Sum of Squared Residuals）\n","  - $||\\mathbf{v}||_{2}^{2}$ や $\\mathbf{v}^{T}\\mathbf{v}$ は、残差ベクトル v の二乗ノルムを表します。\n","\n","  - これは、残差をすべて二乗して足し合わせたもので、モデルで説明しきれなかった全誤差の総量です。\n","\n","$$\\mathbf{v}^{T}\\mathbf{v} = \\sum_{i=1}^{n} v_{i}^{2} = (\\text{残差の二乗和})$$\n","\n","#### 3-2. 分母：自由度（Degrees of Freedom）n−m\n","  - この分母 n−m が、この式の最も重要なポイントです。\n","\n","英語 (English)\t日本語訳 (Japanese Translation)\t解説\n","Note that n−m represents the degrees of freedom\tn−m は自由度を表すことに注意してください。\n","\n","\n","\n","n： 観測値の数（データ点の数）\n","\n","m： 推定した未知のパラメーターの数（係数の数）\n","\n","【なぜ n ではなく n−m で割るのか？（自由度の考え方）】\n","\n","もし誤差が真の値からのズレだったら： もし私たちがすべてのデータの「真の値」を知っていて、そこからのズレ（誤差）を計算した場合、その分散は n で割るだけで「不偏推定値」になります。\n","\n","しかし、真の値は知らない： LSEでは、残差 v\n","i\n","​\n","  は「真の値からのズレ」ではなく、「推定したモデルからのズレ」です。\n","\n","モデルはデータを「学習」する： LSEは m 個の未知のパラメーター（例えば、直線であれば傾きと切片の2つ）を、手元の n 個のデータに最も合うように最適化して推定します。\n","\n","データに合うように m 個のパラメーターを推定した結果、残差は真の誤差よりもわずかに小さくなってしまいます。つまり、分子の $\\sum v_{i}^{2}$ は本来の誤差の総量よりも過小評価されがちです。\n","\n","自由度による補正： m 個のパラメーターを推定するために、データが持つ n の情報の内、m 個を「使って」しまいました。残された、誤差を推定するために「自由に使える」情報の数が n−m です。\n","\n","結論： n−m で割ることで、過小評価された分子を補正し、本来の誤差（分散）に近い、偏りのない（不偏な） 推定値$\\sigma_{l}^{2}$ を得ることができます。\n","\n","\n","\n","#### 4. 推定された係数の共分散行列 $\\mathbf{C}_{\\hat{\\mathbf{x}}}$\n","\n"," $\\sigma_{l}^{2}$ で観測ノイズ全体の大きさがわかったら、いよいよ推定したパラメーター自体の不確かさを計算します。\n","\n","英語 (English)\t日本語訳 (Japanese Translation)\t解説\n","The covariance matrix of the estimated coefficients $\\mathbf{C}_{\\hat{\\mathbf{x}}}$\n","推定された係数の共分散行列$\\mathbf{C}_{\\hat{\\mathbf{x}}}$\n"," \tこの行列は、推定したパラメーター  \n","x\n","^\n","  がどの程度正確であるかを教えてくれます。\n","C\n","x\n","^\n","\n","​\n"," =σ\n","l\n","2\n","​\n"," (A\n","T\n"," A)\n","−1\n"," \tC\n","x\n","^\n","\n","​\n"," =σ\n","l\n","2\n","​\n"," (A\n","T\n"," A)\n","−1\n","\n","\n","Export to Sheets\n","\n","4-1. C\n","x\n","^\n","\n","​\n","  の意味\n","対角要素（Diagonal Elements）： 各パラメーター（x\n","0\n","​\n"," ,x\n","1\n","​\n"," ,⋯）の分散を表します。この値が大きいほど、そのパラメーターの推定値は不確かである、つまり推定誤差が大きいことを意味します。\n","\n","非対角要素（Off-Diagonal Elements）： 異なるパラメーター間の共分散を表します。これは、あるパラメーターが大きくなると別のパラメーターも大きくなる（または小さくなる）という相関関係を示します。\n","\n","4-2. 公式の意味合い\n","C\n","x\n","^\n","\n","​\n"," =σ\n","l\n","2\n","​\n"," ⋅(A\n","T\n"," A)\n","−1\n","\n","\n","σ\n","l\n","2\n","​\n"," ：全体的なノイズの大きさです。当然ながら、観測ノイズが大きいほど、推定されたパラメーターの不確かさも大きくなります。\n","\n","(A\n","T\n"," A)\n","−1\n"," ：これは計画行列 A に基づく項です。A は観測データがモデルパラメーターにどれだけ敏感か（感度）を示す行列でした。この項は、データの配置やモデルの構造が、推定の不確かさにどれだけ影響するかを示します。データがパラメーターの推定に有利な配置であれば、この逆行列は小さな値になり、結果としてパラメーターの不確かさは小さくなります。\n","\n","これらの品質評価基準は、推定したモデルが数学的にどれだけ良い解であるかを客観的に示すために不可欠な指標です。"],"metadata":{"id":"OIf91BvDQdKM"}},{"cell_type":"code","source":[],"metadata":{"id":"FbOGCtsuUHKF"},"execution_count":null,"outputs":[]}]}